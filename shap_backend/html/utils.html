<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>utils API documentation</title>
<meta name="description" content="This file includes functions to improve the handling of shapnet.py" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>utils</code></h1>
</header>
<section id="section-intro">
<p>This file includes functions to improve the handling of shapnet.py</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;This file includes functions to improve the handling of shapnet.py&#34;&#34;&#34;
import pandas as pd
import numpy as np
import shap
__author__ = &#34;Adam Ipkovich&#34;


def read_EW_data(address : str) -&gt; None:
    &#34;&#34;&#34;This function specifically read the data for the EW1 and EW2 models from the collective excel file.
    ## Args:
       - address: The address of the excel file containing the data
    ## Returns:
       - outs (dict[str, dataframe]): A dictionary of the EW1 and EW2 dataframes, containing the multiindexed time series data (variable_name : dataframe)
       - data_desc (dict[str, any]): A dictionary of the variable descriptions
       - data (dict[str, dataframe]): A dictionary of the input dataframes (variable_name : dataframe)
    &#34;&#34;&#34;

    outs = {}
    data_desc = {}
    data = {}

    xls = pd.ExcelFile(address)
    for i in xls.sheet_names:
        ## Construct a pandas dataframe from the excel sheet!
        temp = pd.read_excel(address, engine=&#34;openpyxl&#34;, sheet_name=i, header=None)  ## read with pandas

        ## Get the variable names and descriptions -&gt; the first 5 rows are metadata
        val_cols = temp.iloc[4, -3::].tolist()
        val_cols[0] = i
        data_desc[i] = temp.loc[0:3, 2:3].to_dict()

        ## Start building the individual dataframe
        temp = temp.drop([0, 1, 2, 3, 4]) ##
        temp.iloc[0, -3::] = val_cols
        temp.columns = temp.iloc[0, :]
        temp = temp.iloc[1:, :]
        temp.drop(columns=val_cols[-2::], inplace=True)

        ## Generally speaking, to enable scenario based evaluation, the data includes a column for the scenario name. We currently only use the fisrt &#34;BAU&#34; column
        ## that is not necessary the data from the simulation tool. This allows for implementing a scenario-based evlauation in the future.

        temp.reset_index(inplace=True, drop=True)

        ## Note: Can only handle ISO, Year, Item as multiindexing
        ## try catch is not necessarily a good practice.
        if &#34;ISO&#34; in temp.columns.to_list():
            temp.loc[:, &#34;ISO&#34;] = temp.loc[0, &#34;ISO&#34;]

        if &#34;Year&#34; in temp.columns.to_list():
            if temp.loc[:, &#34;Year&#34;].isna().any():
                try:
                    for j in range(2000, 2020):
                        temp.loc[:, &#34;Year&#34;] = temp.loc[:, &#34;Year&#34;].fillna(value=j, limit=2)

                except:
                    pass
            temp = temp.loc[temp.loc[:, &#34;Year&#34;] &lt; 2020, :]

        if &#34;Item&#34; in temp.columns.to_list():
            if temp.loc[:, &#34;Item&#34;].isna().any():
                try:
                    for i in temp.loc[:, &#34;Item&#34;].unique():
                        if i != &#39;nan&#39;:
                            temp.loc[:, &#34;Item&#34;] = temp.loc[:, &#34;Item&#34;].fillna(value=i,
                                                                             limit=temp.loc[:, &#34;Year&#34;].unique().shape[
                                                                                       0] - 1)
                except:
                    pass

        n_ind = []
        for k in [&#34;ISO&#34;, &#34;Year&#34;, &#34;Item&#34;]:
            if k in temp.columns.to_list():
                # This is bad practice, but it works
                try:
                    n_ind.append(temp.columns.to_list().index(k))
                except:
                    pass
        nn_ind = []
        for k in n_ind:
            nn_ind.append(temp.columns.to_list()[k])

        if i == &#34;EW1&#34; or i == &#34;EW2&#34;:
            outs[i] = temp.reset_index(drop=True).set_index(pd.MultiIndex.from_frame(temp.loc[:, nn_ind])).drop(
                columns=nn_ind).astype(float)
        else:
            data[i] = temp.reset_index(drop=True).set_index(pd.MultiIndex.from_frame(temp.loc[:, nn_ind])).drop(
                columns=nn_ind).astype(float)

    return outs, data_desc, data

def ShapleyExplainability(sv):
    &#34;&#34;&#34;This function calculates the explainability of the shapley values. It is a simple normalization (mean of absolute values).
    ## Args:
    - sv (pd.DataFrame): Shapley values
    ## Returns:
    - np.array: A numpy array of normalized explainability values&#34;&#34;&#34;
    return (np.mean(np.abs(sv.values), axis=0)) #*2 / y_mn*100



def TSFunc(o_var:str, df:pd.DataFrame, func:callable=None, item:str=None, input_vars:dict={}, expl:dict={}, shapley:dict={}, change_expl:dict={}):
    &#34;&#34;&#34;This function is a wrapper to generalize evaluating expert-defined model. It calculates the Shapley values for the given function,
     depending on the input variables, and adds them to global variables, while returning the output value. If there are multi-indexed data, then it tries to calculate the shapley for each Item.

     ## Args:
     - o_var (str): variable/function name (same az the output variable name)
     - df (pd.DataFrame): input data
     - func (callable): function to be calculated - optional
     - item (str): indicator for multiindexing
     - input_vars (dict[var_name:str, pd.DataFrame]): dictionary of input variables (containing relevant data) -&gt; dependency injection, it IS a global variable required for the analysis.
     - expl (dict[var_name:str, pd.DataFrame]): dictionary of the explainer objects, relevant to SHAP -&gt; dependency injection, it IS a global variable required for the analysis.
     - shapley (dict[var_name:str, pd.DataFrame]): dictionary of the shapley values -&gt; dependency injection, it IS a global variable required for the analysis.
     - change_expl (dict[var_name:str, pd.DataFrame]): dictionary of the explainability values -&gt; dependency injection, it IS a global variable required for the analysis.
     ## Returns:
     - y (pd.DataFrame): The output data

     &#34;&#34;&#34;
    y = func(df)
    if func is None:
        func = eval(o_var)
    try:
        ex = shap.Explainer(func, df)  ## build an explainer object
        sv = ex(df)  # calculate the shapley values

        ## if the data focuses on a specific item, then we need to handle it differently
        if item is not None:
            try:
                idx = item.split(&#34;_&#34;)[1] ### if the item has a name with a specifier befor the item type.
            except:
                idx = item ## otherwise continue with the item!

            input_vars[o_var + &#34;_&#34; + idx] = df.columns.tolist()
            expl[o_var + &#34;_&#34; + idx] = ex
            shapley[o_var + &#34;_&#34; + idx] = sv

            change_expl[o_var + &#34;_&#34; + idx] = ShapleyExplainability(sv)  ## scale the shapley values

        else:  ## if the data is not multi-indexed, then we can simply calculate the shapley values
            input_vars[o_var] = df.columns.tolist()
            expl[o_var] = ex
            shapley[o_var] = sv
            change_expl[o_var] = ShapleyExplainability(sv)
    ## otherwise handle buggy/inconsistent data as zero
    except:
        input_vars[o_var] = df.columns.tolist()
        expl[o_var] = 0
        shapley[o_var] = np.zeros((50, 1))
        change_expl[o_var] = np.zeros((len(df.columns.tolist())))
    return y
    # CI[out_var+ &#34;_&#34; + i] = ew_funcs.CI(df)

def compile_input_dataframe():
    &#34;&#34;&#34;Automatically compiles input dataframes from the input variable dictionary.&#34;&#34;&#34;
    raise NotImplementedError(&#34;This function is not implemented yet!&#34;)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="utils.ShapleyExplainability"><code class="name flex">
<span>def <span class="ident">ShapleyExplainability</span></span>(<span>sv)</span>
</code></dt>
<dd>
<div class="desc"><p>This function calculates the explainability of the shapley values. It is a simple normalization (mean of absolute values).</p>
<h2 id="args">Args:</h2>
<ul>
<li>sv (pd.DataFrame): Shapley values</li>
</ul>
<h2 id="returns">Returns:</h2>
<ul>
<li>np.array: A numpy array of normalized explainability values</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def ShapleyExplainability(sv):
    &#34;&#34;&#34;This function calculates the explainability of the shapley values. It is a simple normalization (mean of absolute values).
    ## Args:
    - sv (pd.DataFrame): Shapley values
    ## Returns:
    - np.array: A numpy array of normalized explainability values&#34;&#34;&#34;
    return (np.mean(np.abs(sv.values), axis=0)) #*2 / y_mn*100</code></pre>
</details>
</dd>
<dt id="utils.TSFunc"><code class="name flex">
<span>def <span class="ident">TSFunc</span></span>(<span>o_var: str, df: pandas.core.frame.DataFrame, func: <built-in function callable> = None, item: str = None, input_vars: dict = {}, expl: dict = {}, shapley: dict = {}, change_expl: dict = {})</span>
</code></dt>
<dd>
<div class="desc"><p>This function is a wrapper to generalize evaluating expert-defined model. It calculates the Shapley values for the given function,
depending on the input variables, and adds them to global variables, while returning the output value. If there are multi-indexed data, then it tries to calculate the shapley for each Item.</p>
<h2 id="args">Args:</h2>
<ul>
<li>o_var (str): variable/function name (same az the output variable name)</li>
<li>df (pd.DataFrame): input data</li>
<li>func (callable): function to be calculated - optional</li>
<li>item (str): indicator for multiindexing</li>
<li>input_vars (dict[var_name:str, pd.DataFrame]): dictionary of input variables (containing relevant data) -&gt; dependency injection, it IS a global variable required for the analysis.</li>
<li>expl (dict[var_name:str, pd.DataFrame]): dictionary of the explainer objects, relevant to SHAP -&gt; dependency injection, it IS a global variable required for the analysis.</li>
<li>shapley (dict[var_name:str, pd.DataFrame]): dictionary of the shapley values -&gt; dependency injection, it IS a global variable required for the analysis.</li>
<li>change_expl (dict[var_name:str, pd.DataFrame]): dictionary of the explainability values -&gt; dependency injection, it IS a global variable required for the analysis.</li>
</ul>
<h2 id="returns">Returns:</h2>
<ul>
<li>y (pd.DataFrame): The output data</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def TSFunc(o_var:str, df:pd.DataFrame, func:callable=None, item:str=None, input_vars:dict={}, expl:dict={}, shapley:dict={}, change_expl:dict={}):
    &#34;&#34;&#34;This function is a wrapper to generalize evaluating expert-defined model. It calculates the Shapley values for the given function,
     depending on the input variables, and adds them to global variables, while returning the output value. If there are multi-indexed data, then it tries to calculate the shapley for each Item.

     ## Args:
     - o_var (str): variable/function name (same az the output variable name)
     - df (pd.DataFrame): input data
     - func (callable): function to be calculated - optional
     - item (str): indicator for multiindexing
     - input_vars (dict[var_name:str, pd.DataFrame]): dictionary of input variables (containing relevant data) -&gt; dependency injection, it IS a global variable required for the analysis.
     - expl (dict[var_name:str, pd.DataFrame]): dictionary of the explainer objects, relevant to SHAP -&gt; dependency injection, it IS a global variable required for the analysis.
     - shapley (dict[var_name:str, pd.DataFrame]): dictionary of the shapley values -&gt; dependency injection, it IS a global variable required for the analysis.
     - change_expl (dict[var_name:str, pd.DataFrame]): dictionary of the explainability values -&gt; dependency injection, it IS a global variable required for the analysis.
     ## Returns:
     - y (pd.DataFrame): The output data

     &#34;&#34;&#34;
    y = func(df)
    if func is None:
        func = eval(o_var)
    try:
        ex = shap.Explainer(func, df)  ## build an explainer object
        sv = ex(df)  # calculate the shapley values

        ## if the data focuses on a specific item, then we need to handle it differently
        if item is not None:
            try:
                idx = item.split(&#34;_&#34;)[1] ### if the item has a name with a specifier befor the item type.
            except:
                idx = item ## otherwise continue with the item!

            input_vars[o_var + &#34;_&#34; + idx] = df.columns.tolist()
            expl[o_var + &#34;_&#34; + idx] = ex
            shapley[o_var + &#34;_&#34; + idx] = sv

            change_expl[o_var + &#34;_&#34; + idx] = ShapleyExplainability(sv)  ## scale the shapley values

        else:  ## if the data is not multi-indexed, then we can simply calculate the shapley values
            input_vars[o_var] = df.columns.tolist()
            expl[o_var] = ex
            shapley[o_var] = sv
            change_expl[o_var] = ShapleyExplainability(sv)
    ## otherwise handle buggy/inconsistent data as zero
    except:
        input_vars[o_var] = df.columns.tolist()
        expl[o_var] = 0
        shapley[o_var] = np.zeros((50, 1))
        change_expl[o_var] = np.zeros((len(df.columns.tolist())))
    return y
    # CI[out_var+ &#34;_&#34; + i] = ew_funcs.CI(df)</code></pre>
</details>
</dd>
<dt id="utils.compile_input_dataframe"><code class="name flex">
<span>def <span class="ident">compile_input_dataframe</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Automatically compiles input dataframes from the input variable dictionary.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compile_input_dataframe():
    &#34;&#34;&#34;Automatically compiles input dataframes from the input variable dictionary.&#34;&#34;&#34;
    raise NotImplementedError(&#34;This function is not implemented yet!&#34;)</code></pre>
</details>
</dd>
<dt id="utils.read_EW_data"><code class="name flex">
<span>def <span class="ident">read_EW_data</span></span>(<span>address: str) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>This function specifically read the data for the EW1 and EW2 models from the collective excel file.</p>
<h2 id="args">Args:</h2>
<ul>
<li>address: The address of the excel file containing the data</li>
</ul>
<h2 id="returns">Returns:</h2>
<ul>
<li>outs (dict[str, dataframe]): A dictionary of the EW1 and EW2 dataframes, containing the multiindexed time series data (variable_name : dataframe)</li>
<li>data_desc (dict[str, any]): A dictionary of the variable descriptions</li>
<li>data (dict[str, dataframe]): A dictionary of the input dataframes (variable_name : dataframe)</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read_EW_data(address : str) -&gt; None:
    &#34;&#34;&#34;This function specifically read the data for the EW1 and EW2 models from the collective excel file.
    ## Args:
       - address: The address of the excel file containing the data
    ## Returns:
       - outs (dict[str, dataframe]): A dictionary of the EW1 and EW2 dataframes, containing the multiindexed time series data (variable_name : dataframe)
       - data_desc (dict[str, any]): A dictionary of the variable descriptions
       - data (dict[str, dataframe]): A dictionary of the input dataframes (variable_name : dataframe)
    &#34;&#34;&#34;

    outs = {}
    data_desc = {}
    data = {}

    xls = pd.ExcelFile(address)
    for i in xls.sheet_names:
        ## Construct a pandas dataframe from the excel sheet!
        temp = pd.read_excel(address, engine=&#34;openpyxl&#34;, sheet_name=i, header=None)  ## read with pandas

        ## Get the variable names and descriptions -&gt; the first 5 rows are metadata
        val_cols = temp.iloc[4, -3::].tolist()
        val_cols[0] = i
        data_desc[i] = temp.loc[0:3, 2:3].to_dict()

        ## Start building the individual dataframe
        temp = temp.drop([0, 1, 2, 3, 4]) ##
        temp.iloc[0, -3::] = val_cols
        temp.columns = temp.iloc[0, :]
        temp = temp.iloc[1:, :]
        temp.drop(columns=val_cols[-2::], inplace=True)

        ## Generally speaking, to enable scenario based evaluation, the data includes a column for the scenario name. We currently only use the fisrt &#34;BAU&#34; column
        ## that is not necessary the data from the simulation tool. This allows for implementing a scenario-based evlauation in the future.

        temp.reset_index(inplace=True, drop=True)

        ## Note: Can only handle ISO, Year, Item as multiindexing
        ## try catch is not necessarily a good practice.
        if &#34;ISO&#34; in temp.columns.to_list():
            temp.loc[:, &#34;ISO&#34;] = temp.loc[0, &#34;ISO&#34;]

        if &#34;Year&#34; in temp.columns.to_list():
            if temp.loc[:, &#34;Year&#34;].isna().any():
                try:
                    for j in range(2000, 2020):
                        temp.loc[:, &#34;Year&#34;] = temp.loc[:, &#34;Year&#34;].fillna(value=j, limit=2)

                except:
                    pass
            temp = temp.loc[temp.loc[:, &#34;Year&#34;] &lt; 2020, :]

        if &#34;Item&#34; in temp.columns.to_list():
            if temp.loc[:, &#34;Item&#34;].isna().any():
                try:
                    for i in temp.loc[:, &#34;Item&#34;].unique():
                        if i != &#39;nan&#39;:
                            temp.loc[:, &#34;Item&#34;] = temp.loc[:, &#34;Item&#34;].fillna(value=i,
                                                                             limit=temp.loc[:, &#34;Year&#34;].unique().shape[
                                                                                       0] - 1)
                except:
                    pass

        n_ind = []
        for k in [&#34;ISO&#34;, &#34;Year&#34;, &#34;Item&#34;]:
            if k in temp.columns.to_list():
                # This is bad practice, but it works
                try:
                    n_ind.append(temp.columns.to_list().index(k))
                except:
                    pass
        nn_ind = []
        for k in n_ind:
            nn_ind.append(temp.columns.to_list()[k])

        if i == &#34;EW1&#34; or i == &#34;EW2&#34;:
            outs[i] = temp.reset_index(drop=True).set_index(pd.MultiIndex.from_frame(temp.loc[:, nn_ind])).drop(
                columns=nn_ind).astype(float)
        else:
            data[i] = temp.reset_index(drop=True).set_index(pd.MultiIndex.from_frame(temp.loc[:, nn_ind])).drop(
                columns=nn_ind).astype(float)

    return outs, data_desc, data</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="utils.ShapleyExplainability" href="#utils.ShapleyExplainability">ShapleyExplainability</a></code></li>
<li><code><a title="utils.TSFunc" href="#utils.TSFunc">TSFunc</a></code></li>
<li><code><a title="utils.compile_input_dataframe" href="#utils.compile_input_dataframe">compile_input_dataframe</a></code></li>
<li><code><a title="utils.read_EW_data" href="#utils.read_EW_data">read_EW_data</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>